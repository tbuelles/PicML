{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6791bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 18:01:32.766902: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv1D, Conv2D, MaxPooling2D, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import HyperParameters, RandomSearch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "from itertools import product, permutations, combinations\n",
    "from functools import partial\n",
    "import math\n",
    "import random\n",
    "from scipy.linalg import null_space, det\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "# pd.set_option('display.max_rows', 50)\n",
    "# pd.set_option('display.min_rows', 20)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fcc8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 20\n",
    "MIN_VERTICES, MAX_VERTICES = 4, 14\n",
    "MAX_PLUECKER_LEN = 364\n",
    "COMB_DICT = {k: list(combinations(range(k), k-3)) for k in range(MIN_VERTICES, MAX_VERTICES+1)}\n",
    "\n",
    "def to_matrix(s):\n",
    "    \"\"\" Convert string of list of lists to np.array \"\"\"\n",
    "    res = np.array(literal_eval(s))\n",
    "    return res.astype(np.float32)\n",
    "\n",
    "def to_array(s):\n",
    "    \"\"\" Convert string of list of lists to np.array \"\"\"\n",
    "    return list(literal_eval(s))\n",
    "\n",
    "def to_pad(x):\n",
    "    \"\"\" Return array with zeros \"\"\"\n",
    "    return x + [0] * (MAX_PLUECKER_LEN - len(x))\n",
    "\n",
    "def pad(df):\n",
    "    \"\"\" Pad df with zeros \"\"\"\n",
    "    res = df.copy()\n",
    "    res[\"pad\"] = res[\"pluecker\"].apply(to_pad)\n",
    "    return res \n",
    "\n",
    "def vert(df):\n",
    "    df[\"vert\"] = df[\"matrix\"].apply(lambda x: len(x[0]))\n",
    "    return df\n",
    "\n",
    "def norm(p):\n",
    "    df[\"norm\"] = df[\"pad\"].apply(lambda p: np.array(p) * MAX_PLUECKER_LEN / np.sum(np.abs(p)))\n",
    "    return df\n",
    "\n",
    "def perm(n=10):\n",
    "    perm_dict = {}\n",
    "    for k in range(MIN_VERTICES, MAX_VERTICES+1):\n",
    "        perm_dict[k] = [list(np.random.permutation(range(k))) for _ in range(n)]\n",
    "    return perm_dict\n",
    "\n",
    "\n",
    "def array_to_kernel(mat):\n",
    "    n = len(mat[0])\n",
    "    A = matrix(ZZ, mat).transpose()\n",
    "    A_null = A.integer_kernel() # (n-3) x n\n",
    "    return Matrix(A_null.basis())\n",
    "\n",
    "def matrix_to_pluecker(B):\n",
    "    k = B.ncols()\n",
    "    res = []\n",
    "    for c in COMB_DICT[k]:\n",
    "        minor = B[:, c]\n",
    "        res.append(minor.det())\n",
    "    return res\n",
    "\n",
    "def augment_pluecker(df, n=10):\n",
    "    \"\"\" Compute integer kernel, augment with n random permutations, compute Pluecker coordinate \"\"\"\n",
    "    perm_dict = perm(n)\n",
    "    res = []\n",
    "    for _, row in df.iterrows():\n",
    "        mat, pic = row[\"matrix\"], row[\"pic\"]\n",
    "        B = array_to_kernel(mat)\n",
    "        k = B.ncols()\n",
    "        perm_row = DataFrame([(mat, matrix_to_pluecker(B[:, p]), pic) for p in perm_dict.get(k, [])], columns=[\"matrix\", \"pluecker\", \"pic\"])\n",
    "        res.append(perm_row)\n",
    "    return pd.concat(res, ignore_index=True)\n",
    "\n",
    "# Train / Validation Split for CNN\n",
    "def train_val_cnn(data, n=24, unique=True):\n",
    "    train, val = train_test_split(data, test_size=0.1, random_state=1)\n",
    "    train = augment(train, n=n, unique=unique)\n",
    "    val = pad(val)\n",
    "    X_train, X_val, y_train, y_val = train[\"pad\"], val[\"pad\"], train[\"pic\"], val[\"pic\"]\n",
    "    X_train, X_val = np.stack(X_train), np.stack(X_val)\n",
    "    y_train, y_val = keras.utils.to_categorical(y_train), keras.utils.to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "    X_train, X_val = X_train.reshape(X_train.shape + (1,)), X_val.reshape(X_val.shape + (1,))\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "# Train / Validation Split for Pluecker\n",
    "def train_val_pluecker(df, n=10, test_size=0.1, seed=1):\n",
    "    train, val = train_test_split(df, test_size=test_size, random_state=seed)\n",
    "    train, val = augment_pluecker(train, n=n), augment_pluecker(val, n=n)\n",
    "    train, val = pad(train), pad(val)\n",
    "    train_file = \"../data/train_\" + str(n) + \"_seed\" + str(seed) + \".csv\"\n",
    "    val_file = \"../data/val_\" + str(n) + \"_seed\" + str(seed) + \".csv\"\n",
    "    train.to_csv(train_file, index=False)\n",
    "    val.to_csv(val_file, index=False)\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3e7009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 32s, sys: 2.92 s, total: 5min 35s\n",
      "Wall time: 5min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# DATA\n",
    "CONVERTERS = {\"pad\": literal_eval} # {col: literal_eval for col in [\"matrix\", \"pad\", \"pic\"]}\n",
    "df = pd.read_csv(\"../data/Pic4319.csv\", converters={\"matrix\":literal_eval}, header=None, names=[\"matrix\", \"pic\"])\n",
    "# PLUECKER REPRESENTATION\n",
    "train = pd.read_csv(\"../data/train_100_seed1.csv\", converters=CONVERTERS)\n",
    "val = pd.read_csv(\"../data/val_100_seed1.csv\", converters=CONVERTERS)\n",
    "\n",
    "# NUMBER OF VERTICES\n",
    "# train, val = vert(train), vert(val)\n",
    "\n",
    "# NORMALIZE\n",
    "# train, val = norm(train), norm(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d0857d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multiclass Classification with CNN / MLP\n",
    "\n",
    "def prep_data(data):\n",
    "    X_train, X_val, y_train, y_val = data\n",
    "    X_train, X_val = np.stack(X_train), np.stack(X_val)\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "    y_val = keras.utils.to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "    return (X_train, X_val, y_train, y_val)\n",
    "\n",
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    \"\"\" Callback to plot the learning curves of the model during training.\"\"\"\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if \"val\" not in x]\n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        clear_output(wait=True)\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs[\"val_\" + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics[\"val_\" + metric], \n",
    "                            label=\"val_\" + metric)\n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "def act_fn(x):\n",
    "    return keras.activations.relu(x,alpha=1e-2) # leaky-ReLU activation\n",
    "\n",
    "def width_acc(y_val, y_pred, width=1):\n",
    "    diff = K.abs(K.argmax(y_pred, axis=-1) - K.argmax(y_val, axis=-1))\n",
    "    res = tf.math.count_nonzero(K.less_equal(diff, width))\n",
    "    return int(res) / int(tf.shape(y_pred)[0])\n",
    "\n",
    "def cnn_model(input_shape, lr=1e-3):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128, 3, activation=act_fn, input_shape=input_shape))\n",
    "    # model.add(MaxPooling2D(pool_size=(1,1)), padding=\"valid\")\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=act_fn))\n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def mlp_model(input_shape, units_list=[64, 64, 64, 64], lr=1e-3):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    for units in units_list:\n",
    "        model.add(Dense(units=units, activation=act_fn))\n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\", width_acc])\n",
    "    return model\n",
    "\n",
    "def train_model(model, data, batch_size=64, epochs=100, lr=1e-3):\n",
    "    histories = []\n",
    "    callbacks_list = [PlotLearning(), EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1)]\n",
    "    print(model.summary())\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                        batch_size=batch_size, epochs=epochs,\n",
    "                     verbose=1, shuffle=True, callbacks=callbacks_list)\n",
    "    histories.append(hist.history)\n",
    "    return model, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74daca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 100)               36500     \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 20)                2020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,520\n",
      "Trainable params: 38,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "   37/12147 [..............................] - ETA: 16s - loss: 3.0922 - accuracy: 0.0929 - width_acc: 0.2610    "
     ]
    }
   ],
   "source": [
    "batch_size, epochs, lr = 32, 100, 1e-2\n",
    "units_list = [100] * 1\n",
    "data = prep_data((train[\"norm\"], val[\"norm\"], train[\"pic\"], val[\"pic\"]))\n",
    "input_shape = (MAX_PLUECKER_LEN,)\n",
    "model = mlp_model(input_shape=input_shape, units_list=units_list)\n",
    "model, histories = train_model(model, data, batch_size=batch_size, epochs=epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81da2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
