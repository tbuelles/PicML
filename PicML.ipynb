{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "001540ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.min_rows', 20)\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Polygon/PolygonML.py\n",
    "'''Process Polygon data, select investigations to run, perform ML'''\n",
    "'''Code comprised of 4 cells: \n",
    "    ~ Cell 1 --> Choose investigation parameters\n",
    "    ~ Cell 2 --> Import libraries & data\n",
    "    ~ Cell 3 --> Define the ML function\n",
    "    ~ Cell 4 --> Iterate through selected investigations performing the ML\n",
    "    To run: Select the investigations to consider in cell 1, run cell 1, run cell 2, run cell 3, run cell 4,\n",
    "            ...then can repeatedly edit investigations in cell 1 then running cells 1 & 4 sequentially to perform different ML investigations.\n",
    "    notes:  ensure path to datafile is correct on line 33, there is functionality for padding (although not used in investigations as performed worse),\n",
    "    ...can input padding choice into function directly in cell 4, additional printing options at end of ML function and end of cell 4 which can be uncommented.\n",
    "'''\n",
    "#Select investigations to run\n",
    "input_set = [1,2]       #...select 1 --> vertices, or 2 --> pluckers, or both\n",
    "output_set = [7,8,9,10] #...select 7 --> volume, 8 --> dual volume, 9 --> gorenstein index, 10 --> codimension, or any combination thereof\n",
    "number_vertex_set = [3,4,5,6] #...select which datasets of polygons with this many vertices to consider, note including '0' will run ML on all polygons using vector padding (can edit padding functionality in function call: what choice of number to pad with)\n",
    "crossval_check = True   #...select whether to perform cross-validation, default is 5-fold (can edit in function directly)\n",
    "tt_ratio_set = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]    #...if running over varying train/test split ratios (where no cross-validation, st k=1) select the train set proportions to consider from the interval (0,1)\n",
    "gcd_scheme = 0          #...select which gcd augmentaion scheme to use: 0 --> none, 1 --> pairwise gcds, 2 --> (n-1)-gcds\n",
    "inversion_check = False #...choose whether to run the inversion investigation, swapping the final vector entry with the learned parameter\n",
    "\n",
    "#%%\n",
    "#Import libraries\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from math import floor\n",
    "from itertools import chain, combinations\n",
    "from copy import deepcopy\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "#Import Polygon Data\n",
    "with sqlite3.connect(\"./dim_2_plucker.db\") as db: #...ensure this is the correct path to the datafile\n",
    "    c = db.cursor()\n",
    "    df = pd.read_sql_query(\"SELECT * FROM dim_2_plucker\", db)   #...read database into a pandas dataframe\n",
    "    headings = df.columns.values                                #...save the headings of each column in the table\n",
    "    data = df.values                                            #...convert pandas dataframe to np.array\n",
    "del(c,df)\n",
    "#Reformat dual volume data to floats\n",
    "for polygon in data:\n",
    "    if isinstance(polygon[8],str): #...where dual volume interpreted as string convert to a float\n",
    "        polygon[8] = float(polygon[8].split('/')[0])/float(polygon[8].split('/')[1])\n",
    "del(polygon)\n",
    "\n",
    "#Extract the ranges of the polygon parameters\n",
    "Y_Ranges = [[min([poly[i] for poly in data]),max([poly[i] for poly in data])] for i in [3,4,5,6,7,8,9,10]]\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#%% #ML data - set-up general function for all investigations\n",
    "def ML(X=2,Y=7,poly_n=0,Pad=1,Pchoice=0,gcd=0,k_cv=5,split=0.8):\n",
    "    #Extract relevant parts of data to ML \n",
    "    #Data selection hyper-params\n",
    "    X_choice, Y_choice = X, Y   #...choose what to ML (use 'headings': id, vertices, plucker, plucker_len, num_vertices, num_points, num_interior_points, volume, dual_volume, gorenstein_idx, codimension)\n",
    "    n = poly_n                  #...select number of vertices to ML, use '0' to mean all\n",
    "    Pad_check = Pad             #...true to perform padding, false to select according to length\n",
    "    Pad_choice = Pchoice        #...number to pad onto end of vectors, only relevant when padding\n",
    "    GCD_scheme = gcd             #...whether to augment plucker coords by: (0) nothing, (1) pairwise gcds, (2) (n-1)-gcds\n",
    "    Y_choice_range = Y_Ranges[Y_choice-3][1] - Y_Ranges[Y_choice-3][0] #... (max - min) for the selected varible to ML\n",
    "\n",
    "    #Extract relevant X & Y data\n",
    "    polygons_X, polygons_Y, last_poly_pts = [], [], []\n",
    "    for idx, poly in enumerate(data):\n",
    "        if int(poly[4]) == n or n == 0: #...extract only polygons with n vertices, or all polygons if n==0 (inefficient extra 'ifs' but this section is not the time bottleneck)\n",
    "            if X_choice == 1 and poly[1]!=last_poly_pts: #...skip repeated lines in dataset (where plucker coords permuted)\n",
    "                last_poly_pts = poly[1] #...keep track of last polygon, so know when moved onto next one\n",
    "                polygons_X.append(list(chain(*literal_eval(poly[X_choice])))) #...if using vertices need to flatten to a vector                    \n",
    "                polygons_Y.append(poly[Y_choice])\n",
    "            elif X_choice == 2: \n",
    "                if GCD_scheme == 1:   #...augment vectors with pairwise gcds\n",
    "                    polygons_X.append(literal_eval(poly[X_choice])+[np.gcd(*np.absolute(x)) for x in combinations(literal_eval(poly[X_choice]),2)])\n",
    "                elif GCD_scheme == 2: #...augment vectors with (n-1)-gcds\n",
    "                    polygons_X.append(literal_eval(poly[X_choice])+[np.gcd.reduce(np.absolute(x)) for x in combinations(literal_eval(poly[2]),poly[3]-1)])\n",
    "                else: polygons_X.append(literal_eval(poly[X_choice]))\n",
    "                polygons_Y.append(poly[Y_choice])\n",
    "    number_polygon = len(polygons_Y)\n",
    "    \n",
    "    #Run inversion, editing data accordingly swapping param with last entry of the input vector\n",
    "    if inversion_check:\n",
    "        params = deepcopy(polygons_Y)\n",
    "        for poly in range(len(polygons_X)):\n",
    "            polygons_Y[poly] = polygons_X[poly][-1]\n",
    "            polygons_X[poly][-1] = params[poly]\n",
    "        Y_choice_range = max(polygons_Y)-min(polygons_Y)\n",
    "        del(params)\n",
    "\n",
    "    #Pad plucker coordinates if desired (only needed for n == 0)\n",
    "    if Pad_check and n != 0:\n",
    "        max_length = max(map(len,polygons_X))\n",
    "        for polygon in polygons_X:\n",
    "            while len(polygon) < max_length: #...pad all X vectors to the maximum length\n",
    "                polygon += [Pad_choice]\n",
    "        del(polygon,poly)\n",
    "\n",
    "    #k-fold cross-val data setup\n",
    "    k = k_cv #...number of cross-validations to perform\n",
    "    tt_split = split #... only relevant if no cross-validation, sets the size of the train:test ratio split\n",
    "    ML_data = [[polygons_X[index],polygons_Y[index]] for index in range(number_polygon)]\n",
    "\n",
    "    np.random.shuffle(ML_data)\n",
    "    Training_data, Training_values, Testing_data, Testing_values = [], [], [], []\n",
    "    if k > 1:\n",
    "        s = int(floor(len(ML_data)/k))        #...number of datapoints in each validation split\n",
    "        for i in range(k):\n",
    "            Training_data.append([HS[0] for HS in ML_data[:i*s]]+[HS[0] for HS in ML_data[(i+1)*s:]])\n",
    "            Training_values.append([HS[1] for HS in ML_data[:i*s]]+[HS[1] for HS in ML_data[(i+1)*s:]])\n",
    "            Testing_data.append([HS[0] for HS in ML_data[i*s:(i+1)*s]])\n",
    "            Testing_values.append([HS[1] for HS in ML_data[i*s:(i+1)*s]])\n",
    "    elif k == 1:\n",
    "        s = int(floor(len(ML_data)*tt_split)) #...number of datapoints in train split\n",
    "        Training_data.append([HS[0] for HS in ML_data[:s]])\n",
    "        Training_values.append([HS[1] for HS in ML_data[:s]])\n",
    "        Testing_data.append([HS[0] for HS in ML_data[s:]])\n",
    "        Testing_values.append([HS[1] for HS in ML_data[s:]])\n",
    "\n",
    "    #Create and Train NN\n",
    "    #Define NN hyper-parameters\n",
    "    def act_fn(x): return keras.activations.relu(x,alpha=0.01) #...leaky-ReLU activation\n",
    "    number_of_epochs = 20           #...number of times to run training data through NN\n",
    "    size_of_batches = 32            #...number of datapoints the NN sees per iteration of optimiser (high batch means more accurate param updating, but less frequently) \n",
    "    layer_sizes = [64,64,64,64]     #...number and size of the dense NN layers\n",
    "\n",
    "    #Define lists to record training history and learning measures\n",
    "    hist_data = []               #...training data (output of .fit(), used for plotting)\n",
    "    metric_loss_data = []        #...list of learning measure losses [MAE,logcosh,MAPE,MSE]\n",
    "    acc_list = []                #...list of accuracy ranges [\\pm 0.5, \\pm 5%, \\pm 10%]\n",
    "\n",
    "    #Train k independent NNs for k-fold cross-validation (learning measures then averaged over)\n",
    "    for i in range(k):\n",
    "        #Setup NN\n",
    "        model = keras.Sequential()\n",
    "        for layer_size in layer_sizes:\n",
    "            model.add(keras.layers.Dense(layer_size, activation=act_fn))\n",
    "            #model.add(keras.layers.Dropout(0.1)) #...dropout layer to reduce chance of overfitting to training data\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        model.compile(optimizer='adam', loss='logcosh') #...choose from: [MAE,MAPE,MSE,logcosh]\n",
    "        #Train NN\n",
    "        hist_data.append(model.fit(Training_data[i], Training_values[i], batch_size=size_of_batches, epochs=number_of_epochs, shuffle=True, validation_split=0., verbose=0))\n",
    "        #Test NN\n",
    "        predictions = np.ndarray.flatten(model.predict(Testing_data[i]))\n",
    "        metric_loss_data.append([float(keras.losses.MAE(Testing_values[i],predictions)),float(keras.losses.logcosh(Testing_values[i],predictions)),float(keras.losses.MAPE(Testing_values[i],predictions)),float(keras.losses.MSE(Testing_values[i],predictions))])\n",
    "        count_A, count_B, count_C = 0, 0, 0\n",
    "        for test in range(len(predictions)):\n",
    "            if Testing_values[i][test]-0.5 <= predictions[test] <= Testing_values[i][test]+0.5:\n",
    "                count_A += 1\n",
    "                count_B += 1\n",
    "                count_C += 1\n",
    "            elif Testing_values[i][test]-Y_choice_range*0.025 <= predictions[test] <= Testing_values[i][test]+Y_choice_range*0.025:\n",
    "                count_B += 1\n",
    "                count_C += 1\n",
    "            elif Testing_values[i][test]-Y_choice_range*0.05 <= predictions[test] <= Testing_values[i][test]+Y_choice_range*0.05:\n",
    "                count_C += 1\n",
    "        acc_list.append([count_A/len(predictions),count_B/len(predictions),count_C/len(predictions)])\n",
    "\n",
    "    #Output averaged testing metric accuracies and losses\n",
    "    with open('./MLResults.txt','a') as myfile:\n",
    "        myfile.write('Accuracies [\\pm 0.5, \\pm 0.025*range, \\pm 0.05*range]: '+str(np.sum(acc_list,axis=0)/k)+'\\nLosses [MAE, Log(cosh), MAPE, MSE]: '+str(np.sum(metric_loss_data,axis=0)/k))\n",
    "    #print('\\n####################################') #...uncomment to print measures as the investigations are running\n",
    "    #print('Hyper-params:',headings[X_choice],'-->',headings[Y_choice],', with number vertices:',n,', for dataset size:',number_polygon,'polygons, with...',Pad_check,Pad_choice,Selection_len)\n",
    "    #print('Average measures:')\n",
    "    #print('[MAE, Log(cosh), MAPE, MSE]:',np.sum(metric_loss_data,axis=0)/k)\n",
    "    #print('Accuracies [\\pm 0.5, \\pm 0.025*range, \\pm 0.05*range]:',np.sum(acc_list,axis=0)/k)\n",
    "\n",
    "    return [[X_choice,Y_choice,n],np.sum(acc_list,axis=0)/k,np.sum(metric_loss_data,axis=0)/k] #[[X_choice,Y_choice,n],Testing_values[-1],list(predictions)] #...optionally output true & predicted values for plotting\n",
    "\n",
    "###############################################################################\n",
    "#%% #Set-up file to write results to\n",
    "with open('./MLResults.txt','w') as myfile:\n",
    "    myfile.write('ML Results for Vert/Pluck --> Params, for n 3->6 in Dense LeakyReLU NN 4x64')\n",
    "\n",
    "#Run ML for variety of investigation hyper-params\n",
    "ML_results = [] #...save all investigation information\n",
    "for x in input_set: \n",
    "    for y in output_set: \n",
    "        with open('./MLResults.txt','a') as myfile:\n",
    "            myfile.write('\\n\\n#####################\\nHyper-params: '+str(headings[x])+' --> '+str(headings[y]))\n",
    "        for n in number_vertex_set:\n",
    "            with open('./MLResults.txt','a') as myfile:\n",
    "                myfile.write('\\nn = '+str(n)+': ')\n",
    "            if crossval_check:\n",
    "                ML_results.append(ML(x,y,n,gcd=gcd_scheme))\n",
    "            else:\n",
    "                for tt in tt_ratio_set:\n",
    "                    with open('./MLResults.txt','a') as myfile:\n",
    "                        myfile.write('\\nTrain proportion = '+str(tt)+': ')\n",
    "                    ML_results.append(ML(x,y,n,gcd=gcd_scheme,k_cv=1,split=tt))\n",
    "\n",
    "#Output the results in a raw format for data processing if desired\n",
    "with open('./RawOutput.txt','w') as myfile2:\n",
    "    myfile2.write(str(ML_results))\n",
    "\n",
    "#print(ML_results) #...uncomment if wish to see all investigation information printed to current terminal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "6fcc8f1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matrix</th>\n",
       "      <th>pic</th>\n",
       "      <th>len</th>\n",
       "      <th>norm</th>\n",
       "      <th>pad</th>\n",
       "      <th>flat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[1.0, 0.0, 0.0, -1.0], [0.0, 1.0, 0.0, -1.0],...</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>[1.7320508, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[-1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[1.0, 1.0, 1.0, -3.0], [0.0, 4.0, 0.0, -4.0],...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[6.4031243, 4.1231055, 4.1231055, 1.0, 0.0, 0....</td>\n",
       "      <td>[[-3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[-3.0, -4.0, -4.0, 1.0, 0.0, 4.0, 1.0, 4.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[1.0, 0.0, 0.0, -2.0], [0.0, 1.0, 0.0, -2.0],...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>[3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[-2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[-2.0, -2.0, -1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[1.0, 1.0, 1.0, -5.0], [0.0, 3.0, 0.0, -6.0],...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[8.3666, 3.1622777, 3.1622777, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[-5.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[-5.0, -6.0, -3.0, 1.0, 0.0, 3.0, 1.0, 3.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[1.0, 0.0, 0.0, -4.0], [0.0, 1.0, 0.0, -4.0],...</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[6.4031243, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[-4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[-4.0, -4.0, -3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[1.0, 1.0, 0.0, -8.0], [0.0, 3.0, 0.0, -12.0]...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>[14.73092, 1.0, 3.1622777, 1.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[-8.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[-8.0, -12.0, -3.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[1.0, 0.0, 0.0, -3.0], [0.0, 1.0, 0.0, -1.0],...</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>[3.3166249, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[-3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[-3.0, -1.0, -1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[1.0, 1.0, 1.0, -5.0], [0.0, 2.0, 2.0, -4.0],...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[8.774964, 6.4031243, 2.236068, 1.0, 0.0, 0.0,...</td>\n",
       "      <td>[[-5.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[-5.0, -4.0, -6.0, 1.0, 2.0, 6.0, 1.0, 2.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[1.0, 0.0, 0.0, -4.0], [0.0, 1.0, 0.0, -2.0],...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>[4.582576, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[-4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[-4.0, -2.0, -1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[1.0, 1.0, 1.0, -7.0], [0.0, 2.0, 2.0, -6.0],...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[10.049875, 4.582576, 2.236068, 1.0, 0.0, 0.0,...</td>\n",
       "      <td>[[-7.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[-7.0, -6.0, -4.0, 1.0, 2.0, 4.0, 1.0, 2.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>[[1.0, 0.0, 0.0, -1.0, 2.0, 1.0, 1.0, -1.0, -1...</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.7320508, 2.4494898, 1.414213...</td>\n",
       "      <td>[[-2.0, 2.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[-2.0, 1.0, 1.0, 2.0, -1.0, -1.0, 1.0, -1.0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1...</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>[1.7320508, 1.4142135, 1.7320508, 1.4142135, 1...</td>\n",
       "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0...</td>\n",
       "      <td>[-1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1....</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1.7320508, 1.7320508, 1.7320508, 1.4142135, 1...</td>\n",
       "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>[[1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 1.0, -1.0, 0....</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>[1.4142135, 1.4142135, 1.0, 1.0, 1.7320508, 1....</td>\n",
       "      <td>[[-1.0, 1.0, 0.0, -1.0, -1.0, 1.0, -1.0, 0.0, ...</td>\n",
       "      <td>[-1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 0.0, -1.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>[[1.0, 0.0, 0.0, 1.0, 1.0, -1.0, 1.0, 0.0, -1....</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>[1.4142135, 2.4494898, 1.0, 1.4142135, 1.41421...</td>\n",
       "      <td>[[-2.0, 1.0, -1.0, 0.0, -1.0, -1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[-2.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>[[1.0, 0.0, 0.0, 1.0, 0.0, 1.0, -1.0, 0.0, -1....</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>[1.4142135, 1.7320508, 1.0, 1.4142135, 1.41421...</td>\n",
       "      <td>[[-1.0, -1.0, -1.0, 0.0, -1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>[-1.0, -1.0, 1.0, -1.0, -1.0, 0.0, -1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>[[1.0, 0.0, 0.0, 1.0, 1.0, -1.0, -1.0, 0.0, -1...</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>[1.4142135, 1.7320508, 1.0, 1.0, 1.0, 1.414213...</td>\n",
       "      <td>[[1.0, 0.0, -1.0, -1.0, 1.0, 1.0, 0.0, -1.0, 0...</td>\n",
       "      <td>[1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>[[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>[1.4142135, 1.7320508, 1.4142135, 1.0, 1.41421...</td>\n",
       "      <td>[[-1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[-1.0, 1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>[[1.0, 0.0, 0.0, -1.0, 1.0, 1.0, -1.0, -1.0, -...</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>[1.4142135, 1.0, 1.0, 1.7320508, 1.0, 1.414213...</td>\n",
       "      <td>[[1.0, -1.0, 0.0, -1.0, -1.0, 1.0, 1.0, 0.0, 0...</td>\n",
       "      <td>[1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.0, -1.0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1....</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>[1.4142135, 1.4142135, 1.7320508, 1.7320508, 1...</td>\n",
       "      <td>[[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0...</td>\n",
       "      <td>[-1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4319 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 matrix  pic  len  \\\n",
       "0     [[1.0, 0.0, 0.0, -1.0], [0.0, 1.0, 0.0, -1.0],...   19    4   \n",
       "1     [[1.0, 1.0, 1.0, -3.0], [0.0, 4.0, 0.0, -4.0],...    1    4   \n",
       "2     [[1.0, 0.0, 0.0, -2.0], [0.0, 1.0, 0.0, -2.0],...   18    4   \n",
       "3     [[1.0, 1.0, 1.0, -5.0], [0.0, 3.0, 0.0, -6.0],...    4    4   \n",
       "4     [[1.0, 0.0, 0.0, -4.0], [0.0, 1.0, 0.0, -4.0],...   16    4   \n",
       "5     [[1.0, 1.0, 0.0, -8.0], [0.0, 3.0, 0.0, -12.0]...   10    4   \n",
       "6     [[1.0, 0.0, 0.0, -3.0], [0.0, 1.0, 0.0, -1.0],...   19    4   \n",
       "7     [[1.0, 1.0, 1.0, -5.0], [0.0, 2.0, 2.0, -4.0],...    1    4   \n",
       "8     [[1.0, 0.0, 0.0, -4.0], [0.0, 1.0, 0.0, -2.0],...   18    4   \n",
       "9     [[1.0, 1.0, 1.0, -7.0], [0.0, 2.0, 2.0, -6.0],...    3    4   \n",
       "...                                                 ...  ...  ...   \n",
       "4309  [[1.0, 0.0, 0.0, -1.0, 2.0, 1.0, 1.0, -1.0, -1...    9   14   \n",
       "4310  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1...   11   12   \n",
       "4311  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1....    9   12   \n",
       "4312  [[1.0, 0.0, 0.0, 1.0, -1.0, 0.0, 1.0, -1.0, 0....   11   12   \n",
       "4313  [[1.0, 0.0, 0.0, 1.0, 1.0, -1.0, 1.0, 0.0, -1....    9   13   \n",
       "4314  [[1.0, 0.0, 0.0, 1.0, 0.0, 1.0, -1.0, 0.0, -1....    9   12   \n",
       "4315  [[1.0, 0.0, 0.0, 1.0, 1.0, -1.0, -1.0, 0.0, -1...   11   12   \n",
       "4316  [[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0...   10   12   \n",
       "4317  [[1.0, 0.0, 0.0, -1.0, 1.0, 1.0, -1.0, -1.0, -...   10   13   \n",
       "4318  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1....   10   13   \n",
       "\n",
       "                                                   norm  \\\n",
       "0     [1.7320508, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1     [6.4031243, 4.1231055, 4.1231055, 1.0, 0.0, 0....   \n",
       "2     [3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     [8.3666, 3.1622777, 3.1622777, 1.0, 0.0, 0.0, ...   \n",
       "4     [6.4031243, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "5     [14.73092, 1.0, 3.1622777, 1.0, 0.0, 0.0, 0.0,...   \n",
       "6     [3.3166249, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "7     [8.774964, 6.4031243, 2.236068, 1.0, 0.0, 0.0,...   \n",
       "8     [4.582576, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9     [10.049875, 4.582576, 2.236068, 1.0, 0.0, 0.0,...   \n",
       "...                                                 ...   \n",
       "4309  [1.0, 1.0, 1.0, 1.7320508, 2.4494898, 1.414213...   \n",
       "4310  [1.7320508, 1.4142135, 1.7320508, 1.4142135, 1...   \n",
       "4311  [1.7320508, 1.7320508, 1.7320508, 1.4142135, 1...   \n",
       "4312  [1.4142135, 1.4142135, 1.0, 1.0, 1.7320508, 1....   \n",
       "4313  [1.4142135, 2.4494898, 1.0, 1.4142135, 1.41421...   \n",
       "4314  [1.4142135, 1.7320508, 1.0, 1.4142135, 1.41421...   \n",
       "4315  [1.4142135, 1.7320508, 1.0, 1.0, 1.0, 1.414213...   \n",
       "4316  [1.4142135, 1.7320508, 1.4142135, 1.0, 1.41421...   \n",
       "4317  [1.4142135, 1.0, 1.0, 1.7320508, 1.0, 1.414213...   \n",
       "4318  [1.4142135, 1.4142135, 1.7320508, 1.7320508, 1...   \n",
       "\n",
       "                                                    pad  \\\n",
       "0     [[-1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "1     [[-3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2     [[-2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "3     [[-5.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4     [[-4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "5     [[-8.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "6     [[-3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "7     [[-5.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "8     [[-4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "9     [[-7.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "...                                                 ...   \n",
       "4309  [[-2.0, 2.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, ...   \n",
       "4310  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0...   \n",
       "4311  [[-1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0,...   \n",
       "4312  [[-1.0, 1.0, 0.0, -1.0, -1.0, 1.0, -1.0, 0.0, ...   \n",
       "4313  [[-2.0, 1.0, -1.0, 0.0, -1.0, -1.0, 1.0, 1.0, ...   \n",
       "4314  [[-1.0, -1.0, -1.0, 0.0, -1.0, 1.0, 0.0, 1.0, ...   \n",
       "4315  [[1.0, 0.0, -1.0, -1.0, 1.0, 1.0, 0.0, -1.0, 0...   \n",
       "4316  [[-1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "4317  [[1.0, -1.0, 0.0, -1.0, -1.0, 1.0, 1.0, 0.0, 0...   \n",
       "4318  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0...   \n",
       "\n",
       "                                                   flat  \n",
       "0     [-1.0, -1.0, -1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0....  \n",
       "1     [-3.0, -4.0, -4.0, 1.0, 0.0, 4.0, 1.0, 4.0, 0....  \n",
       "2     [-2.0, -2.0, -1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0....  \n",
       "3     [-5.0, -6.0, -3.0, 1.0, 0.0, 3.0, 1.0, 3.0, 0....  \n",
       "4     [-4.0, -4.0, -3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0....  \n",
       "5     [-8.0, -12.0, -3.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1...  \n",
       "6     [-3.0, -1.0, -1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0....  \n",
       "7     [-5.0, -4.0, -6.0, 1.0, 2.0, 6.0, 1.0, 2.0, 0....  \n",
       "8     [-4.0, -2.0, -1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0....  \n",
       "9     [-7.0, -6.0, -4.0, 1.0, 2.0, 4.0, 1.0, 2.0, 0....  \n",
       "...                                                 ...  \n",
       "4309  [-2.0, 1.0, 1.0, 2.0, -1.0, -1.0, 1.0, -1.0, -...  \n",
       "4310  [-1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, ...  \n",
       "4311  [-1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0,...  \n",
       "4312  [-1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 0.0, -1.0, 1...  \n",
       "4313  [-2.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1...  \n",
       "4314  [-1.0, -1.0, 1.0, -1.0, -1.0, 0.0, -1.0, 0.0, ...  \n",
       "4315  [1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, ...  \n",
       "4316  [-1.0, 1.0, -1.0, -1.0, 0.0, -1.0, -1.0, 0.0, ...  \n",
       "4317  [1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.0, -1.0, -...  \n",
       "4318  [-1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, ...  \n",
       "\n",
       "[4319 rows x 6 columns]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_matrix(s):\n",
    "    \"\"\"Convert string of list of lists to np.array\n",
    "    \"\"\"\n",
    "    res = np.array(literal_eval(s))\n",
    "    return res.astype(np.float32)\n",
    "\n",
    "def to_norm(x):\n",
    "    \"\"\"Convert np.array x to sorted list of norms of columns\n",
    "    \"\"\"\n",
    "    res = np.linalg.norm(x, axis=0)\n",
    "    np.sort(res)\n",
    "    return np.pad(res[::-1], (0, maxLen - len(res)), mode=\"constant\")\n",
    "\n",
    "def to_pad(x):\n",
    "    \"\"\"Return np.array sorted by norm of columns padded with zeros\"\"\"\n",
    "    x_srt = x[:, np.argsort(np.linalg.norm(x, axis=0))[::-1]]\n",
    "    x_pad = np.pad(x_srt, [(0, 0), (0, maxLen - x.shape[1])], mode=\"constant\")\n",
    "    return x_pad\n",
    "    \n",
    "df = pd.read_csv(\"Pic4319.csv\", converters={\"matrix\":to_matrix}, header=None, names=[\"matrix\", \"pic\"])\n",
    "df[\"len\"] = df[\"matrix\"].apply(lambda x: x.shape[1])\n",
    "maxLen = max(df[\"len\"])\n",
    "df[\"norm\"] = df[\"matrix\"].apply(to_norm)\n",
    "df[\"pad\"] = df[\"matrix\"].apply(to_pad)\n",
    "df[\"flat\"] = df[\"pad\"].apply(lambda x: x.flatten(order=\"F\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "71c7a590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax_pad, ax_norm) = plt.subplots(2, 1)\n",
    "sample = df[[\"pad\", \"norm\"]].sample(n=100)\n",
    "sn.heatmap(sample[\"pad\"].mean(), ax=ax_pad)\n",
    "sn.heatmap([sample[\"norm\"].mean()], ax=ax_norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "64a734ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 2ms/step - loss: 3.9241 - accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 2.4248 - accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 1.7810 - accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 1.2204 - accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.9185 - accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.7661 - accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.0000e+00\n",
      "41/41 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"flat\"], df[\"pic\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "X_train, X_test = np.stack(X_train), np.stack(X_test)\n",
    "number_of_epochs = 20\n",
    "size_of_batches = 32 \n",
    "layer_sizes = [64,64,64,64]\n",
    "# normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "# normalizer.adapt(X_train)\n",
    "# hist_data = []\n",
    "metric_loss_data = []\n",
    "def act_fn(x): return keras.activations.relu(x,alpha=0.01) #...leaky-ReLU activation\n",
    "model = keras.Sequential()\n",
    "# model.add(keras.layers.Dense(64, input_shape=(3, 14)))\n",
    "for layer_size in layer_sizes:\n",
    "    model.add(keras.layers.Dense(layer_size, activation=act_fn))\n",
    "    #model.add(keras.layers.Dropout(0.1)) #...dropout layer to reduce chance of overfitting to training data\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(optimizer='adam', loss='logcosh', metrics=[\"accuracy\"]) #...choose from: [MAE,MAPE,MSE,logcosh]\n",
    "#Train NN\n",
    "model.fit(X_train, y_train, batch_size=size_of_batches, epochs=number_of_epochs)\n",
    "#Test NN\n",
    "predictions = np.ndarray.flatten(model.predict(X_test))\n",
    "metric_loss_data.append([float(keras.losses.MAE(y_test,predictions)),float(keras.losses.logcosh(y_test,predictions)),float(keras.losses.MAPE(y_test,predictions)),float(keras.losses.MSE(y_test,predictions))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "ec0705c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step\n",
      "MAE: 0.13413798730358192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "      <th>diff</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>7</td>\n",
       "      <td>6.3174</td>\n",
       "      <td>0.6826</td>\n",
       "      <td>0.0975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>6</td>\n",
       "      <td>8.5062</td>\n",
       "      <td>2.5062</td>\n",
       "      <td>0.4177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>9</td>\n",
       "      <td>9.7742</td>\n",
       "      <td>0.7742</td>\n",
       "      <td>0.0860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>14</td>\n",
       "      <td>13.2037</td>\n",
       "      <td>0.7963</td>\n",
       "      <td>0.0569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>9</td>\n",
       "      <td>9.5053</td>\n",
       "      <td>0.5053</td>\n",
       "      <td>0.0561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>7</td>\n",
       "      <td>7.3786</td>\n",
       "      <td>0.3786</td>\n",
       "      <td>0.0541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>11</td>\n",
       "      <td>9.4854</td>\n",
       "      <td>1.5146</td>\n",
       "      <td>0.1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>13</td>\n",
       "      <td>10.3853</td>\n",
       "      <td>2.6147</td>\n",
       "      <td>0.2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>6.0904</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>9</td>\n",
       "      <td>9.4347</td>\n",
       "      <td>0.4347</td>\n",
       "      <td>0.0483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>8</td>\n",
       "      <td>8.6874</td>\n",
       "      <td>0.6874</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>9</td>\n",
       "      <td>9.4252</td>\n",
       "      <td>0.4252</td>\n",
       "      <td>0.0472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>11</td>\n",
       "      <td>13.6697</td>\n",
       "      <td>2.6697</td>\n",
       "      <td>0.2427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>7</td>\n",
       "      <td>8.5663</td>\n",
       "      <td>1.5663</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>7</td>\n",
       "      <td>6.4332</td>\n",
       "      <td>0.5668</td>\n",
       "      <td>0.0810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>11</td>\n",
       "      <td>11.5298</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>0.0482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>9</td>\n",
       "      <td>9.6483</td>\n",
       "      <td>0.6483</td>\n",
       "      <td>0.0720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>9</td>\n",
       "      <td>7.3003</td>\n",
       "      <td>1.6997</td>\n",
       "      <td>0.1889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>13</td>\n",
       "      <td>13.8559</td>\n",
       "      <td>0.8559</td>\n",
       "      <td>0.0658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>12</td>\n",
       "      <td>12.0714</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y    pred   diff    err\n",
       "2111   7  6.3174 0.6826 0.0975\n",
       "2296   6  8.5062 2.5062 0.4177\n",
       "1781   9  9.7742 0.7742 0.0860\n",
       "2268  14 13.2037 0.7963 0.0569\n",
       "2387   9  9.5053 0.5053 0.0561\n",
       "2661   7  7.3786 0.3786 0.0541\n",
       "2851  11  9.4854 1.5146 0.1377\n",
       "1336  13 10.3853 2.6147 0.2011\n",
       "17     6  6.0904 0.0904 0.0151\n",
       "3243   9  9.4347 0.4347 0.0483\n",
       "...   ..     ...    ...    ...\n",
       "730    8  8.6874 0.6874 0.0859\n",
       "616    9  9.4252 0.4252 0.0472\n",
       "2525  11 13.6697 2.6697 0.2427\n",
       "1135   7  8.5663 1.5663 0.2238\n",
       "1687   7  6.4332 0.5668 0.0810\n",
       "3866  11 11.5298 0.5298 0.0482\n",
       "4095   9  9.6483 0.6483 0.0720\n",
       "289    9  7.3003 1.6997 0.1889\n",
       "2782  13 13.8559 0.8559 0.0658\n",
       "1432  12 12.0714 0.0714 0.0059\n",
       "\n",
       "[1296 rows x 4 columns]"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample = df.sample(n=1000)\n",
    "# sample_X, sample_y = np.stack(sample[\"flat\"]), sample[\"pic\"]\n",
    "sample_X, sample_y = X_test, y_test\n",
    "sample_pred = np.ndarray.flatten(model.predict(sample_X))\n",
    "res = DataFrame({\"y\": sample_y, \"pred\": sample_pred})\n",
    "res[\"diff\"] = DataFrame.abs(res[\"y\"] - res[\"pred\"])\n",
    "res[\"err\"] = res[\"diff\"] / res[\"y\"]\n",
    "err = res[\"err\"].mean()\n",
    "print(f\"MAE: {err}\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "4cec982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2111     7\n",
       "2296     6\n",
       "1781     9\n",
       "2268    14\n",
       "2387     9\n",
       "2661     7\n",
       "2851    11\n",
       "1336    13\n",
       "17       6\n",
       "3243     9\n",
       "        ..\n",
       "2263     9\n",
       "1247    11\n",
       "1828     8\n",
       "2155     9\n",
       "1995    10\n",
       "3093     9\n",
       "705     12\n",
       "2778    13\n",
       "2136     8\n",
       "881      4\n",
       "Name: pic, Length: 864, dtype: int64"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40501780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
